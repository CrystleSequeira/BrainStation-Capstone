{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 NLP with Wine Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is **Part 2: NLP with Wine Reviews** of the project. In Part 1, I cleaned the data from the jupyter notebook named Part 1: Clean Wine Reviews and I as well considered feature engineering. I extracted the year from the title column to include vintage as a new feature. Now that the data is cleaned, I will need to run NLP (Natural Language Processing) before I can run any machine learning on the data. The text columns in this dataset are Country (i.e. Italy), Province (i.e. Sicily), Variety (i.e. Pinot Noir), and Description (Wine Review). I will use a One-Hot-Encorder process for the Province, Country, and Variety and I will use the TF-IDF process for wine review descriptions.\n",
    "\n",
    "As a reference: The original source of this dataset is from [Here](https://www.kaggle.com/zynicide/wine-reviews)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# NLTK Packages\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load train and test data\n",
    "df_train = pd.read_csv('data/train_clean.csv')\n",
    "df_test = pd.read_csv('data/test_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load y_train and y_test and save them as a column named points in the df dataframe.\n",
    "df_train['points'].to_csv (r'y_train.csv', index = False)\n",
    "df_test['points'].to_csv (r'y_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: (90979, 7)\n",
      "Test set size: (38992, 7)\n"
     ]
    }
   ],
   "source": [
    "# Check the train and test shapes to make sure the column numbers are the same. \n",
    "# As well as the train test should be larger then the test set.\n",
    "print('Train set size:', df_train.shape)\n",
    "print('Test set size:', df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Check Dependent Variable (Wine Scores) distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised Learning fall into either Classification or Regression models. Classification models predict a dependent variable that is categorical, and a Regression model predicts a dependent variable that is a measurement or count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# View the distriubtion of wine scores\n",
    "plt.figure()\n",
    "plt.hist(df_train['points'],10)\n",
    "plt.xlabel('Distribution', fontsize = 16)\n",
    "plt.ylabel('Frequency', fontsize = 16)\n",
    "plt.title('Distribution of Reviewer', fontsize = 18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The wine score ranges between 80 - 100. There are a couple different ways to treat this for predicting the wine scores. 1) Wine method is treat these scores as 20 classifiers which would be very difficult to predict. 2) Another method is to break the scores into \"good\" and \"bad\" scores thus creating a two classifier problem. 3) Model the 80-100 with a regressor model and treat the scores as continuous.\n",
    "\n",
    "I will first start with a two classifier problem where good scores range between 90 - 100 and bad scores range between 80-89. For this setup I will use Logistic Regression, Random Forest, and XGboost to predict the wine scores. If there is more time then I will also try to predict the scores from 80 - 100 by using a regression model such as using KNN Regressor and Random Forest Regressor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Set y values to 0 and 1 (2 classifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make copy of the train/test dataset before making changes to the data\n",
    "df_train_copy = df_train.copy()\n",
    "df_test_copy = df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a new dataframe for setting the distribution of reviewer to 2 classifications\n",
    "df_train_class = df_train.copy()\n",
    "df_test_class = df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>variety</th>\n",
       "      <th>vintage</th>\n",
       "      <th>points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>A very dark color and extremely concentrated f...</td>\n",
       "      <td>42.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Petite Sirah</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>An indifferent wine, hot and baked, with jammy...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Meritage</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Portugal</td>\n",
       "      <td>Dominated by its tannins and woody characteris...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Alentejano</td>\n",
       "      <td>Portuguese Red</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>This wine's unusual purple fruit, citrus, herb...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Malbec</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Italy</td>\n",
       "      <td>Elegant yet extremely accessible, this present...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Central Italy</td>\n",
       "      <td>Lambrusco di Sorbara</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    country                                        description  price  \\\n",
       "0        US  A very dark color and extremely concentrated f...   42.0   \n",
       "1        US  An indifferent wine, hot and baked, with jammy...   10.0   \n",
       "2  Portugal  Dominated by its tannins and woody characteris...   17.0   \n",
       "3        US  This wine's unusual purple fruit, citrus, herb...   30.0   \n",
       "4     Italy  Elegant yet extremely accessible, this present...   30.0   \n",
       "\n",
       "        province               variety  vintage  points  \n",
       "0     California          Petite Sirah   2013.0       1  \n",
       "1     California              Meritage   2009.0       0  \n",
       "2     Alentejano        Portuguese Red   2011.0       0  \n",
       "3     Washington                Malbec   2013.0       0  \n",
       "4  Central Italy  Lambrusco di Sorbara   2010.0       1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map the points to 0 and 1 for train dataset\n",
    "conversion_dict = {80:0, 81:0, 82:0, 83:0, 84:0, 85:0, 86:0, 87:0, 88:0, 89:1, 90:1, 91:1, 92:1, 93:1, 94:1, 95:1, 96:1, 97:1, 98:1, 99:1, 100:1}\n",
    "df_train_class['points'] = df_train_class['points'].map(conversion_dict)\n",
    "\n",
    "# Check to make sure the points have changed to 0 and 1\n",
    "df_train_class.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map the points to 0 and 1 for test dataset\n",
    "conversion_dict = {80:0, 81:0, 82:0, 83:0, 84:0, 85:0, 86:0, 87:0, 88:0, 89:1, 90:1, 91:1, 92:1, 93:1, 94:1, 95:1, 96:1, 97:1, 98:1, 99:1, 100:1}\n",
    "df_test_class['points'] = df_test_class['points'].map(conversion_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# View the distribution of wine scores\n",
    "plt.figure()\n",
    "plt.hist(df_train_class['points'],10)\n",
    "plt.xlabel('Distribution', fontsize = 16)\n",
    "plt.ylabel('Frequency', fontsize = 16)\n",
    "plt.title('Distribution of Reviewer', fontsize = 18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are more \"bad\" reviews than \"good\" reviews therefore the model will be able to predict bad reviews better than reviews that are good. While I could downsample the data to make the total amount of good and bad reviews equal, for now I will keep the data how it is as the difference isn't too \"large\". I will first take a look at the precision and recall scores before downsamplting. The reason for this is because I want to avoid removing data as much as possible because more data points helps improve the training of a model. If the precision and recall scores are low compared to the accuracy score, then I might want to consider downsampling. Note in the future I could also upsample as another approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set y values for test and train\n",
    "y_train = df_train['points']\n",
    "y_test = df_test['points']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set y and test values with only 0 (\"bad\") and 1 (\"good\") values and rename y values so that we keep the original y values.\n",
    "y_train_class = df_train_class['points']\n",
    "y_test_class = df_test_class['points']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>variety</th>\n",
       "      <th>vintage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>A very dark color and extremely concentrated f...</td>\n",
       "      <td>42.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Petite Sirah</td>\n",
       "      <td>2013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>An indifferent wine, hot and baked, with jammy...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Meritage</td>\n",
       "      <td>2009.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Portugal</td>\n",
       "      <td>Dominated by its tannins and woody characteris...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Alentejano</td>\n",
       "      <td>Portuguese Red</td>\n",
       "      <td>2011.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>This wine's unusual purple fruit, citrus, herb...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Malbec</td>\n",
       "      <td>2013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Italy</td>\n",
       "      <td>Elegant yet extremely accessible, this present...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Central Italy</td>\n",
       "      <td>Lambrusco di Sorbara</td>\n",
       "      <td>2010.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    country                                        description  price  \\\n",
       "0        US  A very dark color and extremely concentrated f...   42.0   \n",
       "1        US  An indifferent wine, hot and baked, with jammy...   10.0   \n",
       "2  Portugal  Dominated by its tannins and woody characteris...   17.0   \n",
       "3        US  This wine's unusual purple fruit, citrus, herb...   30.0   \n",
       "4     Italy  Elegant yet extremely accessible, this present...   30.0   \n",
       "\n",
       "        province               variety  vintage  \n",
       "0     California          Petite Sirah   2013.0  \n",
       "1     California              Meritage   2009.0  \n",
       "2     Alentejano        Portuguese Red   2011.0  \n",
       "3     Washington                Malbec   2013.0  \n",
       "4  Central Italy  Lambrusco di Sorbara   2010.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now that we have the y values, drop the points column from the X dataframe\n",
    "X_train = df_train_copy.drop('points', axis = 1)\n",
    "\n",
    "# Repeat with test\n",
    "X_test = df_test_copy.drop('points', axis = 1)\n",
    "\n",
    "# View train dataset to make sure the dataframe looks \"OK\"\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TFIDF Vectorizer package from Sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF Vectorizer will be used for the wine reviews as the process takes a sentance and extracts the word from the sentance and gives it a weight. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/avielstern/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "import nltk\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords \n",
    "ENGLISH_STOP_WORDS = stopwords.words('english')\n",
    "\n",
    "def my_tokenizer(sentence):\n",
    "    \n",
    "    for punctuation_mark in string.punctuation:\n",
    "        # Remove punctuation and set to lower case\n",
    "        sentence = sentence.replace(punctuation_mark,'').lower()\n",
    "\n",
    "    # split sentence into words\n",
    "    listofwords = sentence.split(' ')\n",
    "    listofstemmed_words = []\n",
    "    \n",
    "        \n",
    "    # Remove stopwords and any tokens that are just empty strings\n",
    "    for word in listofwords:\n",
    "        if (not word in ENGLISH_STOP_WORDS) and (word!=''):\n",
    "            # Stem words\n",
    "            stemmed_word = stemmer.stem(word)\n",
    "            listofstemmed_words.append(stemmed_word)\n",
    "\n",
    "    return listofstemmed_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to not use n_grams which finds group of words in a sentance that contains not i.e. will not go back there again. This is because the wine reviews do not have sentiment. Instead the wine reviews give a more professional tone that describes characteristics of the wine such is the wine acidic, are there tannins, fruity, fresh and so on.\n",
    "\n",
    "min_df is a threshold that removes any token that has a frequency less than the given parameter. The default is set to 1 and if the threshold ranges between 0 - 1 as a float than the the threshold is a percentage of the porportion of tokens in a document. If the threshold is set as an int than the threshold is the frequency of tokens a document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate\n",
    "tfidf = TfidfVectorizer(min_df = 0.01, tokenizer=my_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90979, 415)\n",
      "(38992, 415)\n"
     ]
    }
   ],
   "source": [
    "# Create review \n",
    "train_review = X_train['description']\n",
    "test_review = X_test['description']\n",
    "\n",
    "\n",
    "# Fit reviews\n",
    "tfidf.fit(train_review)\n",
    "\n",
    "# Transform reviews\n",
    "review_train = tfidf.transform(train_review)\n",
    "review_test = tfidf.transform(test_review)\n",
    "\n",
    "# Make sure train and test shape contain the same number of rows. \n",
    "# This is just reassurance that the tranformation worked.\n",
    "print(review_train.shape)\n",
    "print(review_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View tokens associated to their weight for the train dataset\n",
    "word_weights = np.array(np.sum(review_train, axis=0)).reshape((-1,))\n",
    "\n",
    "words = np.array(tfidf.get_feature_names())\n",
    "words_df = pd.DataFrame({\"word\": words, \n",
    "                         \"weight\": word_weights})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>332.911648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>408.617714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>372.947815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017</td>\n",
       "      <td>504.512139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018</td>\n",
       "      <td>599.444599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>yet</td>\n",
       "      <td>836.920752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>young</td>\n",
       "      <td>780.630935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>youth</td>\n",
       "      <td>305.916007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>zest</td>\n",
       "      <td>602.166573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>zesti</td>\n",
       "      <td>599.154304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>415 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      word      weight\n",
       "0       10  332.911648\n",
       "1      100  408.617714\n",
       "2     2016  372.947815\n",
       "3     2017  504.512139\n",
       "4     2018  599.444599\n",
       "..     ...         ...\n",
       "410    yet  836.920752\n",
       "411  young  780.630935\n",
       "412  youth  305.916007\n",
       "413   zest  602.166573\n",
       "414  zesti  599.154304\n",
       "\n",
       "[415 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe to a csv which can be used to make further analysis\n",
    "words_df.to_csv (r'NLP_weights_train.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe of the tokenized words. \n",
    "# Will also need to use .toarray() to remove sparcity. \n",
    "\n",
    "description_train = pd.DataFrame(columns=tfidf.get_feature_names(), data=review_train.toarray())\n",
    "description_test = pd.DataFrame(columns=tfidf.get_feature_names(), data=review_test.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>accent</th>\n",
       "      <th>acid</th>\n",
       "      <th>add</th>\n",
       "      <th>...</th>\n",
       "      <th>wood</th>\n",
       "      <th>would</th>\n",
       "      <th>wrap</th>\n",
       "      <th>year</th>\n",
       "      <th>yellow</th>\n",
       "      <th>yet</th>\n",
       "      <th>young</th>\n",
       "      <th>youth</th>\n",
       "      <th>zest</th>\n",
       "      <th>zesti</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.233790</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241324</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125386</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.243582</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90974</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.186656</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90975</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.131732</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.267229</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90976</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.248652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90977</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90978</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.175317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90979 rows  415 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        10  100  2016  2017  2018  2019  2020  accent      acid  add  ...  \\\n",
       "0      0.0  0.0   0.0   0.0   0.0   0.0   0.0     0.0  0.000000  0.0  ...   \n",
       "1      0.0  0.0   0.0   0.0   0.0   0.0   0.0     0.0  0.000000  0.0  ...   \n",
       "2      0.0  0.0   0.0   0.0   0.0   0.0   0.0     0.0  0.000000  0.0  ...   \n",
       "3      0.0  0.0   0.0   0.0   0.0   0.0   0.0     0.0  0.000000  0.0  ...   \n",
       "4      0.0  0.0   0.0   0.0   0.0   0.0   0.0     0.0  0.125386  0.0  ...   \n",
       "...    ...  ...   ...   ...   ...   ...   ...     ...       ...  ...  ...   \n",
       "90974  0.0  0.0   0.0   0.0   0.0   0.0   0.0     0.0  0.186656  0.0  ...   \n",
       "90975  0.0  0.0   0.0   0.0   0.0   0.0   0.0     0.0  0.131732  0.0  ...   \n",
       "90976  0.0  0.0   0.0   0.0   0.0   0.0   0.0     0.0  0.000000  0.0  ...   \n",
       "90977  0.0  0.0   0.0   0.0   0.0   0.0   0.0     0.0  0.000000  0.0  ...   \n",
       "90978  0.0  0.0   0.0   0.0   0.0   0.0   0.0     0.0  0.000000  0.0  ...   \n",
       "\n",
       "           wood  would  wrap      year    yellow       yet  young  youth  \\\n",
       "0      0.000000    0.0   0.0  0.000000  0.000000  0.000000    0.0    0.0   \n",
       "1      0.000000    0.0   0.0  0.000000  0.000000  0.000000    0.0    0.0   \n",
       "2      0.000000    0.0   0.0  0.233790  0.000000  0.000000    0.0    0.0   \n",
       "3      0.241324    0.0   0.0  0.000000  0.000000  0.000000    0.0    0.0   \n",
       "4      0.000000    0.0   0.0  0.000000  0.000000  0.243582    0.0    0.0   \n",
       "...         ...    ...   ...       ...       ...       ...    ...    ...   \n",
       "90974  0.000000    0.0   0.0  0.000000  0.000000  0.000000    0.0    0.0   \n",
       "90975  0.000000    0.0   0.0  0.000000  0.267229  0.000000    0.0    0.0   \n",
       "90976  0.000000    0.0   0.0  0.000000  0.000000  0.248652    0.0    0.0   \n",
       "90977  0.000000    0.0   0.0  0.000000  0.000000  0.000000    0.0    0.0   \n",
       "90978  0.000000    0.0   0.0  0.175317  0.000000  0.000000    0.0    0.0   \n",
       "\n",
       "       zest     zesti  \n",
       "0       0.0  0.000000  \n",
       "1       0.0  0.000000  \n",
       "2       0.0  0.000000  \n",
       "3       0.0  0.000000  \n",
       "4       0.0  0.000000  \n",
       "...     ...       ...  \n",
       "90974   0.0  0.400992  \n",
       "90975   0.0  0.000000  \n",
       "90976   0.0  0.000000  \n",
       "90977   0.0  0.000000  \n",
       "90978   0.0  0.000000  \n",
       "\n",
       "[90979 rows x 415 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To make sure the TF-IDF worked and that the index looks OK, columns looks OK and so on.\n",
    "display(description_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Use One Hot Encoding to transform Province, Country, and Variety into 1 or 0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One Hot Encoding takes a category and assigns it as its own column in a dataframe. The columns are then filled with 1 or 0. To complete this task, I ended up using three approaches for this which resulted into an iterative workflow process. \n",
    "   \n",
    "**Approach 1:** The first approach I used the function pd.get_dummies on Province, Country, and Variety. After applying get_dummies, I concat Province, Country, Variety, Description into one dataframe. The problem that I ran into which I did not forsee was that the test dataset contained different variables than the train dataset which meant the dataframe sizes were different shapes. This happened because when I split the train and test set. This is more likely to happen with columns that have many categories. I became aware of this problem after fitting a model on the train dataset and realizing that the model would not be able to run for the test dataset.\n",
    "\n",
    "In the train dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of countries in train set: 42\n",
      "Number of province in train set: 406\n",
      "Number of variety in train set: 646\n"
     ]
    }
   ],
   "source": [
    "print('Number of countries in train set:', len(df_train['country'].groupby(df_train['country']).count()))\n",
    "print('Number of province in train set:', len(df_train['province'].groupby(df_train['province']).count()))\n",
    "print('Number of variety in train set:', len(df_train['variety'].groupby(df_train['variety']).count()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approach 2:** I then used a second approach to fix this where I set a threshold to remove any countries, provinces, and varieties that has a percentage of less than 0.5% in the total column. While this approach technically \"worked\", two issues arised when completing this task. First, I had to peak into the test dataset to make sure that the same countries, varieties, and provinces were in the train dataset as in the test dataset before running the predictive models. The second issue was that the accuracy score was 50% which is low. The reason for such a low accuracy score is because I removed too many variables when setting the threshold. Countries had dropped from a count of 42 to 12, province had dropped from a count of 406 to 34 and variety had dropped from a count of 646 to 34!\n",
    "    \n",
    "**Approach 3:** Thanks to this [site](https://www.kaggle.com/learn-forum/50008), I found a solution. We can create a train and test set, run get dummies and then create a new dataframe of the test dataset which only includes get_dummy features from the train set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X train dataset: (90979, 1511)\n",
      "Size of X test dataset: (38992, 1351)\n"
     ]
    }
   ],
   "source": [
    "# make copies of X and y dataset so that the original dataset is not changed\n",
    "X_train_copy = X_train.copy()\n",
    "y_train_copy = y_train.copy()\n",
    "\n",
    "X_test_copy = X_test.copy()\n",
    "y_test_copy = y_test.copy()\n",
    "\n",
    "# One hot encoding for country, province, and variety\n",
    "dummy_train = X_train_copy.drop(['description', 'price', 'vintage'], axis = 1)\n",
    "dummy_test = X_test_copy.drop(['description', 'price', 'vintage'], axis = 1)\n",
    "\n",
    "# Add columns country, province, variety\n",
    "cat_columns=[\"country\", \"province\", \"variety\"]\n",
    "\n",
    "# One Hot Encoding\n",
    "dummy_train= pd.get_dummies(dummy_train, prefix_sep=\"__\", columns=cat_columns)\n",
    "\n",
    "cat_columns=[\"country\", \"province\", \"variety\"]\n",
    "dummy_test= pd.get_dummies(dummy_test, prefix_sep=\"__\", columns=cat_columns)\n",
    "\n",
    "# Now that we have use nlp on the text columns, we need to remove these columns\n",
    "X_train_copy.drop(['country', 'description', 'province', 'variety'], axis = 1, inplace = True)\n",
    "X_test_copy.drop(['country', 'description', 'province', 'variety'], axis = 1, inplace = True)\n",
    "\n",
    "# add all columns back to a final X dataframe\n",
    "X_train_final = pd.concat([description_train, dummy_train, X_train_copy], axis = 1, sort = False)\n",
    "X_test_final = pd.concat([description_test, dummy_test, X_test_copy], axis = 1, sort = False)\n",
    "\n",
    "print('Size of X train dataset:', X_train_final.shape)\n",
    "print('Size of X test dataset:', X_test_final.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make copies of X and y dataset so that the original dataset is not changed\n",
    "X_train_copy = X_train.copy()\n",
    "\n",
    "# Set country_name to equal a list of all the country names\n",
    "country_train = X_train_copy['country'].groupby(X_train_copy['country']).count().index\n",
    "\n",
    "# Create a threshold where list equals a percentage of the country names from the entire column\n",
    "list = X_train_copy['country'].groupby(X_train_copy['country']).count() / X_train_copy['country'].count()\n",
    "\n",
    "# Create a list of countries to remove\n",
    "remove_countries = []\n",
    "for i in country_train:\n",
    "    if list[i] < 0.005:\n",
    "        remove_countries.append(i)\n",
    "\n",
    "# Find the index for all countries that need to be removed in that country\n",
    "index = []\n",
    "for i in np.arange(len(X_train_copy)):\n",
    "    for j in np.arange(len(remove_countries)):\n",
    "        if X_train_copy['country'].iloc[i] == remove_countries[j]:\n",
    "            index.append(i)\n",
    "\n",
    "\n",
    "# Drop rows where countries need to be removed\n",
    "X_train_copy.drop(index, axis = 0, inplace = True)\n",
    "\n",
    "# Reset Index\n",
    "X_train_copy = X_train_copy.reset_index()\n",
    "\n",
    "# Drop column named index\n",
    "X_train_copy.drop('index', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make copies of X so that the original dataset is not changed\n",
    "X_test_copy = X_test.copy()\n",
    "\n",
    "# Set country_name to equal a list of all the country names\n",
    "country_test = X_test_copy['country'].groupby(X_test_copy['country']).count().index\n",
    "\n",
    "# Create a threshold where list equals a percentage of the country names from the entire column\n",
    "list = X_test_copy['country'].groupby(X_test_copy['country']).count() / X_test_copy['country'].count()\n",
    "\n",
    "# Create a list of countries to remove\n",
    "remove_countries = []\n",
    "for i in country_test:\n",
    "    if list[i] < 0.005:\n",
    "        remove_countries.append(i)\n",
    "        \n",
    "# Find the index for all countries that need to be removed in that country\n",
    "index = []\n",
    "for i in np.arange(len(X_test_copy)):\n",
    "    for j in np.arange(len(remove_countries)):\n",
    "        if X_test_copy['country'].iloc[i] == remove_countries[j]:\n",
    "            index.append(i)\n",
    "\n",
    "# Drop rows where countries need to be removed\n",
    "X_test_copy.drop(index, axis = 0, inplace = True)\n",
    "\n",
    "# Reset Index\n",
    "X_train_copy = X_train_copy.reset_index()\n",
    "\n",
    "# Drop column named index\n",
    "X_train_copy.drop('index', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of countries in train: 12\n",
      "number of countries in test: 12\n"
     ]
    }
   ],
   "source": [
    "print('number of countries in train:', len(X_train_copy['country'].groupby(X_train_copy['country']).count().index))\n",
    "print('number of countries in test:', len(X_test_copy['country'].groupby(X_test_copy['country']).count().index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set province_name to equal a list of all the province names\n",
    "province_train = X_train_copy['province'].groupby(X_train_copy['province']).count().index\n",
    "\n",
    "# Create a threshold where list equals a percentage of the provinces names from the entire column\n",
    "list = X_train_copy['province'].groupby(X_train_copy['province']).count() / X_train_copy['province'].count()\n",
    "\n",
    "# Create a list of provinces to remove\n",
    "remove_province = []\n",
    "for i in province_train:\n",
    "    if list[i] < 0.005:\n",
    "        remove_province.append(i)\n",
    "        \n",
    "# Find the index for all provinces that need to be removed in that country        \n",
    "index = []\n",
    "for i in np.arange(len(X_train_copy)):\n",
    "    for j in np.arange(len(remove_province)):\n",
    "        if X_train_copy['province'].iloc[i] == remove_province[j]:\n",
    "            index.append(i)   \n",
    "            \n",
    "# Drop rows where provinces need to be removed            \n",
    "X_train_copy = X_train_copy.drop(index, axis = 0)\n",
    "\n",
    "# Reset index\n",
    "X_train_copy = X_train_copy.reset_index()\n",
    "\n",
    "# Drop index column\n",
    "X_train_copy.drop(['index'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set province_name to equal a list of all the province names\n",
    "province_test = X_test_copy['province'].groupby(X_test_copy['province']).count().index\n",
    "\n",
    "# Create a threshold where list equals a percentage of the provinces names from the entire column\n",
    "list = X_test_copy['province'].groupby(X_test_copy['province']).count() / X_test_copy['province'].count()\n",
    "\n",
    "# Create a list of provinces to remove\n",
    "remove_province = []\n",
    "for i in province_test:\n",
    "    if list[i] < 0.005:\n",
    "        remove_province.append(i)\n",
    "\n",
    "# Find the index for all provinces that need to be removed in that country  \n",
    "index = []\n",
    "for i in np.arange(len(X_test_copy)):\n",
    "    for j in np.arange(len(remove_province)):\n",
    "        if X_test_copy['province'].iloc[i] == remove_province[j]:\n",
    "            index.append(i)\n",
    "            \n",
    "# Drop rows where countries need to be removed\n",
    "X_test_copy.drop(index, axis = 0, inplace = True)\n",
    "\n",
    "# Reset index\n",
    "X_test_copy = X_test_copy.reset_index()\n",
    "\n",
    "# Drop index column\n",
    "X_test_copy.drop(['index'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of provinces in train: 34\n"
     ]
    }
   ],
   "source": [
    "print('number of provinces in train:', len(X_train_copy['province'].groupby(X_train_copy['province']).count().index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('number of provinces in test:', len(X_test_copy['province'].groupby(X_test_copy['province']).count().index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set variety_name to equal a list of all the variety names\n",
    "variety_train = X_train_copy['variety'].groupby(X_train_copy['variety']).count().index\n",
    "\n",
    "# Create a threshold where list equals a percentage of the variety names from the entire column\n",
    "list = X_train_copy['variety'].groupby(X_train_copy['variety']).count() / X_train_copy['variety'].count()\n",
    "\n",
    "# Create a list of variety to remove\n",
    "variety = []\n",
    "for i in variety_train:\n",
    "    if X_train_copy['variety'].where(X_train_copy['variety'] == i).count() / len(X_train_copy) < 0.005:\n",
    "        variety.append(i)\n",
    "\n",
    "# Find the index for all varieties that need to be removed in that country \n",
    "index = []\n",
    "for i in np.arange(len(X_train_copy)):\n",
    "    for j in np.arange(len(variety)):\n",
    "        if X_train_copy['variety'].iloc[i] == variety[j]:\n",
    "            index.append(i)\n",
    "            \n",
    "# Drop rows where varietes that need to be removed            \n",
    "X_train_copy.drop(index, axis = 0, inplace = True)\n",
    "\n",
    "# Reset index\n",
    "X_train_copy = X_train_copy.reset_index()\n",
    "\n",
    "# Drop index column\n",
    "X_train_copy.drop(['index'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Originally tried to replace varieties with a low frequency by the top variety that is associated from that province, however this script did not seem to work out correctly.\n",
    "Therefore I ended up dropping the rows with a low frequency which is also not a good data science approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt to replacing variety with a low frequency rather than dropping the row all together:\n",
    "\n",
    "# top_variety = X_train_copy['variety'].groupby(X_train_copy['province']).describe().top\n",
    "\n",
    "# for j in index:\n",
    "#    for i in np.arange(0, len(top_variety)):\n",
    "#        if top_variety.index[i] == X_train_copy['province'].iloc[j]:\n",
    "#            X_train_copy2['variety'] = X_train_copy['variety'].replace(X_train_copy['variety'].iloc[j], top_variety[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set variety_name to equal a list of all the variety names\n",
    "variety_test = X_test_copy['variety'].groupby(X_test_copy['variety']).count().index\n",
    "\n",
    "# Create a threshold where list equals a percentage of the variety names from the entire column\n",
    "list = X_test_copy['variety'].groupby(X_test_copy['variety']).count() / X_test_copy['variety'].count()\n",
    "\n",
    "# Create a list of variety to remove\n",
    "variety = []\n",
    "for i in variety_test:\n",
    "    if list[i] < 0.005:\n",
    "        variety.append(i)\n",
    "        \n",
    "# Find the index for all varieties that need to be removed in that country \n",
    "index = []\n",
    "for i in np.arange(len(X_test_copy)):\n",
    "    for j in np.arange(len(variety)):\n",
    "        if X_test_copy['variety'].iloc[i] == variety[j]:\n",
    "            index.append(i)\n",
    "            \n",
    "# Drop rows where varietes that need to be removed      \n",
    "X_test_copy.drop(index, axis = 0, inplace = True)\n",
    "\n",
    "# Reset index\n",
    "X_test_copy = X_test_copy.reset_index()\n",
    "\n",
    "# Drop index column\n",
    "X_test_copy.drop(['index'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of varieties for train: 34\n",
      "number of varieties for test: 35\n"
     ]
    }
   ],
   "source": [
    "# Check to see if the number of varieties that started at 502 has decreased\n",
    "print('number of varieties for train:', len(X_train_copy['variety'].groupby(X_train_copy['variety']).count()))\n",
    "print('number of varieties for test:', len(X_test_copy['variety'].groupby(X_test_copy['variety']).count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test dataset had Tampranillo Blend and Tampranillo, whereas the train dataset had only the Tempranillo. To fix this, I can replace the Tempranillo blend as Tempranillo for the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace Tempranillo Blend to Tempranillo\n",
    "X_test_copy['variety'].replace('Tempranillo Blend', 'Tempranillo', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 779,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to make sure that the number of different varieties has changed to 34\n",
    "len(X_test_copy['variety'].groupby(X_test_copy['variety']).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>province</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>California</td>\n",
       "      <td>Petite Sirah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>California</td>\n",
       "      <td>Meritage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Portugal</td>\n",
       "      <td>Alentejano</td>\n",
       "      <td>Portuguese Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Malbec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Italy</td>\n",
       "      <td>Central Italy</td>\n",
       "      <td>Lambrusco di Sorbara</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    country       province               variety\n",
       "0        US     California          Petite Sirah\n",
       "1        US     California              Meritage\n",
       "2  Portugal     Alentejano        Portuguese Red\n",
       "3        US     Washington                Malbec\n",
       "4     Italy  Central Italy  Lambrusco di Sorbara"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One hot encoding for country, province, and variety like completed in Approach 1\n",
    "\n",
    "# Create a dataframe of just country, province, and variety\n",
    "dummy_train = X_train.drop(['description', 'price', 'vintage'], axis = 1)\n",
    "dummy_test = X_test.drop(['description', 'price', 'vintage'], axis = 1)\n",
    "\n",
    "# View train dataframe to make sure that this worked\n",
    "dummy_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_dummies for all three columns\n",
    "cat_columns=[\"country\", \"province\", \"variety\"]\n",
    "dummy_train= pd.get_dummies(dummy_train, prefix_sep=\"__\", columns=cat_columns)\n",
    "\n",
    "cat_columns=[\"country\", \"province\", \"variety\"]\n",
    "dummy_test= pd.get_dummies(dummy_test, prefix_sep=\"__\", columns=cat_columns)\n",
    "\n",
    "final_train, final_test = dummy_train.align(dummy_test, join='inner', axis=1)  # inner join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export file to be used for the future. \n",
    "# This is needed when importing a new dataset as it will be used as part of the .align function\n",
    "final_train.to_csv(r'dummy_train.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set size: (90979, 853)\n",
      "test set size: (38992, 853)\n"
     ]
    }
   ],
   "source": [
    "# Check to make sure they are the same size!\n",
    "print('train set size:', final_train.shape)\n",
    "print('test set size:', final_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have use nlp on the text columns, we need to remove these columns\n",
    "X_train.drop(['country', 'description', 'province', 'variety'], axis = 1, inplace = True)\n",
    "X_test.drop(['country', 'description', 'province', 'variety'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add all columns back to a final X dataframe\n",
    "X_train_final = pd.concat([description_train, final_train, X_train], axis = 1, sort = False)\n",
    "X_test_final = pd.concat([description_test, final_test, X_test], axis = 1, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add y values back to train and test set before exporting dataframe as csv file\n",
    "\n",
    "# Create a copy of the train and test dataset to rename the dataframes\n",
    "train = X_train_final.copy()\n",
    "test = X_test_final.copy()\n",
    "\n",
    "# Add points to train and test set where y values are 0 and 1\n",
    "train['points'] = y_train_class\n",
    "test['points'] = y_test_class\n",
    "\n",
    "train.to_csv (r'model_train.csv', index = False)\n",
    "test.to_csv (r'model_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat for regression dataset\n",
    "train = X_train_final.copy()\n",
    "test = X_test_final.copy()\n",
    "\n",
    "train['points'] = y_train\n",
    "test['points'] = y_test\n",
    "\n",
    "train.to_csv (r'model_train_regression.csv', index = False)\n",
    "test.to_csv (r'model_test_regression.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a function to be used for future datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do not need to split dataset into train and test because this will be used with a dataset where the models have already been trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wine_review(csv_file_name):\n",
    "\n",
    "    # load data\n",
    "    df = pd.read_csv(csv_file_name)\n",
    "\n",
    "    # Load train dummy dataset so that we create an inner join later \n",
    "    df = pd.read_csv('dummy_train.csv')\n",
    "    \n",
    "    # Set points as a 0 and 1\n",
    "    df_class = df.copy()\n",
    "    # map the points to 0 and 1 for test dataset\n",
    "    conversion_dict = {80:0, 81:0, 82:0, 83:0, 84:0, 85:0, 86:0, 87:0, 88:0, 89:1, 90:1, 91:1, 92:1, 93:1, 94:1, 95:1, 96:1, 97:1, 98:1, 99:1, 100:1}\n",
    "    df_class['points'] = df_class['points'].map(conversion_dict)\n",
    "    \n",
    "    # Set X and y\n",
    "    X = df_class.drop(['Unnamed: 0','points'], axis = 1)\n",
    "    y = df_class['points']\n",
    "   \n",
    "    # TFIDF\n",
    "    import string\n",
    "\n",
    "    import nltk\n",
    "    stemmer = nltk.stem.PorterStemmer()\n",
    "\n",
    "    nltk.download('stopwords')\n",
    "    from nltk.corpus import stopwords \n",
    "    ENGLISH_STOP_WORDS = stopwords.words('english')\n",
    "\n",
    "    def my_tokenizer(sentence):\n",
    "    \n",
    "        for punctuation_mark in string.punctuation:\n",
    "            # Remove punctuation and set to lower case\n",
    "            sentence = sentence.replace(punctuation_mark,'').lower()\n",
    "\n",
    "        # split sentence into words\n",
    "        listofwords = sentence.split(' ')\n",
    "        listofstemmed_words = []\n",
    "    \n",
    "        \n",
    "        # Remove stopwords and any tokens that are just empty strings\n",
    "        for word in listofwords:\n",
    "            if (not word in ENGLISH_STOP_WORDS) and (word!=''):\n",
    "                # Stem words\n",
    "                stemmed_word = stemmer.stem(word)\n",
    "                listofstemmed_words.append(stemmed_word)\n",
    "\n",
    "        return listofstemmed_words\n",
    "\n",
    "\n",
    "    review = X['description']\n",
    "\n",
    "    # Fit positive reviews\n",
    "    tfidf.fit(review)\n",
    "\n",
    "    # Transform positive reviews\n",
    "    review_tfidf = tfidf.transform(review)\n",
    "\n",
    "    description = pd.DataFrame(columns=tfidf.get_feature_names(), data=review_tfidf.toarray())\n",
    "    \n",
    "    # One hot encoding for country, province, and variety like completed in Approach 1\n",
    "\n",
    "    # Create a dataframe of just country, province, and variety\n",
    "    dummy = X.drop(['description', 'price', 'vintage'], axis = 1)\n",
    "    \n",
    "    # get_dummies for all three columns\n",
    "    cat_columns=[\"country\", \"province\", \"variety\"]\n",
    "    dummy =  pd.get_dummies(dummy, prefix_sep=\"__\", columns=cat_columns)\n",
    "\n",
    "    train, final_X = dummy_train.align(dummy, join='inner', axis=1)  # inner join \n",
    "\n",
    "    # Now that we have use nlp on the text columns, we need to remove these columns\n",
    "    X.drop(['country', 'description', 'province', 'variety'], axis = 1, inplace = True)\n",
    "    \n",
    "    # add all columns back to a final X dataframe\n",
    "    X_final = pd.concat([description, final_X, X], axis = 1, sort = False)\n",
    "    \n",
    "    # Create a copy of the train and test dataset to rename the dataframes\n",
    "    df = X_final.copy()\n",
    "\n",
    "    # Add points to train and test set where y values are 0 and 1\n",
    "    df['points'] = y\n",
    "\n",
    "    # Export train dataset as a csv to be used to run in other jupyter notebooks\n",
    "    return train_final.to_csv (r'model_wine_reviews.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
